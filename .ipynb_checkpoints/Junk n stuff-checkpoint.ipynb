{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from math import e\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Epicurious data from [Kaggle](https://www.kaggle.com/hugodarwood/epirecipes). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropping 5 rows...\n"
     ]
    }
   ],
   "source": [
    "raw_data = pd.read_csv('epi_r.csv')\n",
    "full = pd.read_json('full_format_recipes.json')\n",
    "\n",
    "bin_ft = list(raw_data.columns)\n",
    "bin_ft.remove('title')\n",
    "bin_ft.remove('rating')\n",
    "bin_ft.remove('calories')\n",
    "bin_ft.remove('fat')\n",
    "bin_ft.remove('protein')\n",
    "bin_ft.remove('sodium')\n",
    "\n",
    "missing = []\n",
    "for row in raw_data.index:      #Find recipes missing from full-form set\n",
    "    if raw_data.loc[row].title not in list(full.title):\n",
    "        missing.append(row) \n",
    "        \n",
    "\n",
    "print('dropping {} rows...'.format(len(missing)))\n",
    "for row in missing:             #Drop the recipes without full-form available\n",
    "    raw_data = raw_data.drop(row)\n",
    "    \n",
    "full_ind = []\n",
    "for row in raw_data.index:      #Record indices for each full-form recipe in order of csv\n",
    "    full_ind.append(list(full[full.title==raw_data.loc[row].title].index)[0])\n",
    "\n",
    "#Grab wanted data from complete recipes:\n",
    "categories = []\n",
    "directions = []\n",
    "ingredients = []                \n",
    "for i in full_ind:\n",
    "    row = full.loc[i]\n",
    "    cat, dr, ing = row.categories, row.directions, row.ingredients\n",
    "    categories.append(cat)                          #List of categories\n",
    "    directions.append(dr)                           #List of directions\n",
    "    ingredients.append(ing)                         #List of ingredients\n",
    "    \n",
    "raw_data['full_cats'] = categories                  #append to our df\n",
    "raw_data['full_dir'] = directions\n",
    "raw_data['full_ingr'] = ingredients\n",
    "\n",
    "raw_data['four_stars'] = np.where(raw_data.rating>4, 1, 0)\n",
    "raw_data['no_stars'] = np.where(raw_data.rating==0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Basic features: lengths of ingredients list, instruction steps, complete instructions\n",
    "def get_length(lst):\n",
    "    length = 0\n",
    "    for step in lst:\n",
    "        length += len(step)\n",
    "    return length\n",
    "\n",
    "#consolidates directions from list to single string\n",
    "def get_full_dir(lst):\n",
    "    doc = ''\n",
    "    for step in lst:\n",
    "        doc += step + ' '\n",
    "    return doc\n",
    "\n",
    "#Build features\n",
    "raw_data['n_ingredients'] = raw_data.full_ingr.apply(len)\n",
    "raw_data.n_ingredients = raw_data.n_ingredients/raw_data.n_ingredients.max()\n",
    "raw_data['n_steps'] = raw_data.full_dir.apply(len)\n",
    "raw_data.n_steps = raw_data.n_steps/raw_data.n_steps.max()\n",
    "raw_data['n_words'] = raw_data.full_dir.apply(get_length)\n",
    "raw_data.n_words = raw_data.n_words/raw_data.n_words.max()\n",
    "raw_data['dir_doc'] = raw_data.full_dir.apply(get_full_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20047, 5000)\n",
      "most important recipe text features:  ['and pepper', 'cocktail glass', 'heavy large', 'inch', 'into cocktail', 'let cool', 'minutes', 'pepper', 'salt', 'salt and', 'sprinkle', 'stand', 'the', 'until', 'with']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alliedtoasters/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Build tfid vectorizer\n",
    "vctzr = TfidfVectorizer(ngram_range=(1, 3), max_features=5000)\n",
    "vctzr.build_analyzer()\n",
    "\n",
    "#Train on recipe corpus\n",
    "vctzr = vctzr.fit(raw_data.dir_doc)\n",
    "\n",
    "#Get sparse matrix of recipe text features\n",
    "A = vctzr.transform(raw_data.dir_doc)\n",
    "X = A\n",
    "Y = raw_data['no_stars']\n",
    "\n",
    "#Use random forest classifier to select most important models\n",
    "clf = ExtraTreesClassifier(class_weight='balanced')\n",
    "clf.fit(X, Y)\n",
    "\n",
    "sel = SelectFromModel(clf, prefit=True, threshold=.0035)\n",
    "print(X.shape)\n",
    "X_txt = sel.transform(X)\n",
    "X_txt.shape\n",
    "\n",
    "txt_map = list(sel.transform(vctzr.get_feature_names()).ravel())\n",
    "print('most important recipe text features: ', txt_map)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "674\n",
      "(20047, 19)\n",
      "most important categories:\n",
      "alcoholic\n",
      "bake\n",
      "bon appétit\n",
      "cocktail party\n",
      "drink\n",
      "fall\n",
      "gin\n",
      "gourmet\n",
      "house & garden\n",
      "kid-friendly\n",
      "onion\n",
      "peanut free\n",
      "quick & easy\n",
      "sauce\n",
      "sauté\n",
      "summer\n",
      "vegetable\n",
      "vegetarian\n",
      "winter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alliedtoasters/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Find most important features from categories\n",
    "X = raw_data[bin_ft]\n",
    "\n",
    "clf = ExtraTreesClassifier(class_weight='balanced')\n",
    "clf.fit(X, Y)\n",
    "sel = SelectFromModel(clf, prefit=True, threshold=.008)\n",
    "print(len(X.columns))\n",
    "X_cts = sel.transform(X)\n",
    "print(X_cts.shape)\n",
    "\n",
    "#Find the corresponding categories for selected features\n",
    "keepers = sel.transform(range(0, len(bin_ft)))\n",
    "\n",
    "cts_map = []\n",
    "print('most important categories:')\n",
    "for num in keepers.ravel():\n",
    "    cts_map.append(bin_ft[int(num)])\n",
    "    print(bin_ft[int(num)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.78004988,  0.79002494,  0.77625343,  0.79047144,  0.76677476])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Combine all the best features\n",
    "truca = pd.concat([pd.DataFrame(data=X_txt.todense(), columns=txt_map, index=raw_data.index), pd.DataFrame(data=X_cts, columns=cts_map, index=raw_data.index)], axis=1)\n",
    "truca = pd.concat([truca, raw_data[['n_steps', 'n_words', 'n_ingredients']]], axis=1)\n",
    "\n",
    "X = truca\n",
    "Y = raw_data['no_stars']\n",
    "\n",
    "svc = SVC(class_weight='balanced')\n",
    "cross_val_score(svc, X, Y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20047, 5000)\n",
      "most important recipe text features:  ['about', 'add', 'cocktail', 'glass', 'in', 'ingredients', 'into cocktail glass', 'minutes', 'salt', 'stir', 'strain into cocktail', 'the', 'to', 'using']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alliedtoasters/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Get sparse matrix of recipe text features\n",
    "\n",
    "A = vctzr.transform(raw_data.dir_doc)\n",
    "X = A\n",
    "Y = raw_data['four_stars']\n",
    "\n",
    "#Use random forest classifier to select most important models\n",
    "clf = ExtraTreesClassifier(class_weight='balanced')\n",
    "clf.fit(X, Y)\n",
    "\n",
    "sel = SelectFromModel(clf, prefit=True, threshold=.0011)\n",
    "print(X.shape)\n",
    "X_txt = sel.transform(X)\n",
    "X_txt.shape\n",
    "\n",
    "txt_map = list(sel.transform(vctzr.get_feature_names()).ravel())\n",
    "print('most important recipe text features: ', txt_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "674\n",
      "(20047, 15)\n",
      "most important categories:\n",
      "bake\n",
      "bon appétit\n",
      "dairy\n",
      "fall\n",
      "gourmet\n",
      "herb\n",
      "kid-friendly\n",
      "onion\n",
      "quick & easy\n",
      "spring\n",
      "summer\n",
      "tomato\n",
      "vegetarian\n",
      "wheat/gluten-free\n",
      "winter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alliedtoasters/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Find most important features from categories\n",
    "X = raw_data[bin_ft]\n",
    "\n",
    "clf = ExtraTreesClassifier(class_weight='balanced')\n",
    "clf.fit(X, Y)\n",
    "sel = SelectFromModel(clf, prefit=True, threshold=.008)\n",
    "print(len(X.columns))\n",
    "X_cts = sel.transform(X)\n",
    "print(X_cts.shape)\n",
    "\n",
    "#Find the corresponding categories for selected features\n",
    "keepers = sel.transform(range(0, len(bin_ft)))\n",
    "\n",
    "cts_map = []\n",
    "print('most important categories:')\n",
    "for num in keepers.ravel():\n",
    "    cts_map.append(bin_ft[int(num)])\n",
    "    print(bin_ft[int(num)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine all the best features\n",
    "truca = pd.concat([pd.DataFrame(data=X_txt.todense(), columns=txt_map, index=raw_data.index), pd.DataFrame(data=X_cts, columns=cts_map, index=raw_data.index)], axis=1)\n",
    "truca = pd.concat([truca, raw_data[['n_steps', 'n_words', 'n_ingredients']]], axis=1)\n",
    "\n",
    "X = truca\n",
    "Y = raw_data['four_stars']\n",
    "\n",
    "svc = SVC()\n",
    "#cross_val_score(svc, X, Y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [3.945, 3.95, 3.955], 'gamma': [0.0475, 0.045, 0.0425]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mst = pd.concat([truca, raw_data['four_stars']], axis=1)\n",
    "samp = mst.sample(frac=.25)\n",
    "fts = list(samp.columns)\n",
    "fts.remove('four_stars')\n",
    "\n",
    "X=samp[fts]\n",
    "Y=samp['four_stars']\n",
    "\n",
    "svc = SVC()\n",
    "prms = {\n",
    "    'C' : [3.945, 3.95, 3.955],\n",
    "    'gamma' : [.0475, .045, .0425]\n",
    "}\n",
    "srch = GridSearchCV(svc, prms, cv=5)\n",
    "\n",
    "srch.fit(X, Y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57569711178729988"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srch.score(mst[fts], mst['four_stars'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 3.945, 'gamma': 0.0425}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.5719272 ,  0.57844849,  0.56198553,  0.57919681,  0.57046645])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC(C=3.945, gamma=.0425)\n",
    "cross_val_score(svc, mst[fts], mst['four_stars'], cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004053207892648741"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series([ 0.60383944,  0.59790471,  0.6081317 ,  0.59940135,  0.60089798]).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 5, 'degree': 1, 'gamma': 0.1}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.57395859316537789"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mst = pd.concat([truca, raw_data['four_stars']], axis=1)\n",
    "samp = mst.sample(frac=.2)\n",
    "fts = list(samp.columns)\n",
    "fts.remove('four_stars')\n",
    "\n",
    "X=samp[fts]\n",
    "Y=samp['four_stars']\n",
    "\n",
    "svc = SVC(kernel='poly')\n",
    "prms = {\n",
    "    'C' : [1, 5, 10, 15],\n",
    "    'gamma' : [1, .1, .01],\n",
    "    'degree': [1, 2, 3]\n",
    "}\n",
    "srch = GridSearchCV(svc, prms, cv=5)\n",
    "\n",
    "srch.fit(X, Y)\n",
    "\n",
    "print(srch.best_params_)\n",
    "srch.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.57591623,  0.57695186,  0.56847094,  0.58169119,  0.56921926])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_poly = SVC(degree=1, C=5, gamma=.1)\n",
    "cross_val_score(svc_poly, mst[fts], mst['four_stars'], cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 850, 'gamma': 0.0103}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.56572711399351461"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mst = pd.concat([truca, raw_data['four_stars']], axis=1)\n",
    "samp = mst.sample(frac=.2)\n",
    "fts = list(samp.columns)\n",
    "fts.remove('four_stars')\n",
    "\n",
    "X=samp[fts]\n",
    "Y=samp['four_stars']\n",
    "\n",
    "svc = SVC(kernel='sigmoid')\n",
    "prms = {\n",
    "    'C' : [850, 800],\n",
    "    'gamma' : [.0103, .0102]\n",
    "}\n",
    "srch = GridSearchCV(svc, prms, cv=5)\n",
    "\n",
    "srch.fit(X, Y)\n",
    "\n",
    "print(srch.best_params_)\n",
    "srch.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
