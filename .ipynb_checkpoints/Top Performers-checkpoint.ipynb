{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn import random_projection\n",
    "import datetime\n",
    "from math import e\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Epicurious data from [Kaggle](https://www.kaggle.com/hugodarwood/epirecipes). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropping 5 rows...\n"
     ]
    }
   ],
   "source": [
    "raw_data = pd.read_csv('epi_r.csv')\n",
    "full = pd.read_json('full_format_recipes.json')\n",
    "\n",
    "bin_ft = list(raw_data.columns)\n",
    "bin_ft.remove('title')\n",
    "bin_ft.remove('rating')\n",
    "bin_ft.remove('calories')\n",
    "bin_ft.remove('fat')\n",
    "bin_ft.remove('protein')\n",
    "bin_ft.remove('sodium')\n",
    "\n",
    "missing = []\n",
    "for row in raw_data.index:      #Find recipes missing from full-form set\n",
    "    if raw_data.loc[row].title not in list(full.title):\n",
    "        missing.append(row) \n",
    "        \n",
    "\n",
    "print('dropping {} rows...'.format(len(missing)))\n",
    "for row in missing:             #Drop the recipes without full-form available\n",
    "    raw_data = raw_data.drop(row)\n",
    "    \n",
    "full_ind = []\n",
    "for row in raw_data.index:      #Record indices for each full-form recipe in order of csv\n",
    "    full_ind.append(list(full[full.title==raw_data.loc[row].title].index)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grab wanted data from complete recipes:\n",
    "categories = []\n",
    "directions = []\n",
    "ingredients = []\n",
    "ratings = []\n",
    "dates = []\n",
    "descrips = []\n",
    "for i in full_ind:\n",
    "    row = full.loc[i]\n",
    "    categories.append(row.categories)                          #List of categories\n",
    "    directions.append(row.directions)                           #List of directions\n",
    "    ingredients.append(row.ingredients)                         #List of ingredients\n",
    "    descrips.append(row.desc)                            #Description when available\n",
    "    ratings.append(row.rating)                                 #Reconcile mismatched ratings\n",
    "    dates.append(row.date)                                     #Get dates\n",
    "    \n",
    "raw_data['full_cats'] = categories                  #append to our df\n",
    "raw_data['full_dir'] = directions\n",
    "raw_data['full_ingr'] = ingredients\n",
    "raw_data['description'] = descrips\n",
    "raw_data.rating = ratings\n",
    "raw_data['date_'] = dates\n",
    "\n",
    "raw_data['four_stars'] = np.where(raw_data.rating>4, 1, 0)\n",
    "raw_data['no_stars'] = np.where(raw_data.rating==0, 1, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_date = raw_data.date_.max()\n",
    "raw_data.t_delta = latest_date-raw_data.date_\n",
    "raw_data.days_old = raw_data.t_delta.apply(lambda x: x.days)\n",
    "raw_data['age'] = raw_data.days_old/raw_data.days_old.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Basic features: lengths of ingredients list, instruction steps, complete instructions\n",
    "def get_length(lst):\n",
    "    length = 0\n",
    "    for step in lst:\n",
    "        length += len(step)\n",
    "    return length\n",
    "\n",
    "#consolidates directions from list to single string\n",
    "def get_full_dir(lst):\n",
    "    doc = ''\n",
    "    for step in lst:\n",
    "        doc += step + ' '\n",
    "    return doc\n",
    "\n",
    "#Build features\n",
    "raw_data['n_ingredients'] = raw_data.full_ingr.apply(len)\n",
    "raw_data.n_ingredients = raw_data.n_ingredients/raw_data.n_ingredients.max()\n",
    "raw_data['n_steps'] = raw_data.full_dir.apply(len)\n",
    "raw_data.n_steps = raw_data.n_steps/raw_data.n_steps.max()\n",
    "raw_data['n_words'] = raw_data.full_dir.apply(get_length)\n",
    "raw_data.n_words = raw_data.n_words/raw_data.n_words.max()\n",
    "raw_data['n_cats'] = raw_data.full_cats.apply(len)\n",
    "raw_data.n_cats = raw_data.n_cats/raw_data.n_cats.max()\n",
    "raw_data['dir_doc'] = raw_data.full_dir.apply(get_full_dir)\n",
    "\n",
    "raw_data['has_desc'] = np.where(raw_data.description, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = []\n",
    "mean_rating = []\n",
    "class_imb = []\n",
    "rating_std = []\n",
    "freq = []\n",
    "for ft in bin_ft:\n",
    "    cat.append(ft)\n",
    "    df = raw_data[raw_data[ft]==1]\n",
    "    mean_rating.append(df.rating.mean())\n",
    "    class_imb.append(df.four_stars.sum()/len(df))\n",
    "    rating_std.append(df.rating.std())\n",
    "    freq.append(len(df))\n",
    "    \n",
    "result=pd.DataFrame()\n",
    "result['category'] = cat\n",
    "result['mean_rating'] = mean_rating\n",
    "result['class_imbalance'] = class_imb\n",
    "result['rating_std'] = rating_std\n",
    "result['freq'] = freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5371377263430938\n"
     ]
    }
   ],
   "source": [
    "total_class_imb = raw_data.four_stars.sum()/len(raw_data)\n",
    "print(total_class_imb)\n",
    "result['cb_dev'] = abs(total_class_imb - result['class_imbalance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result.loc[result[result.freq>500].cb_dev.sort_values(ascending=False).index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=[\n",
    "    'drink',\n",
    "    'bon appétit',\n",
    "    'gin',\n",
    "    'house & garden',\n",
    "    'alcoholic',\n",
    "    'goat cheese',\n",
    "    'roast',\n",
    "    'family reunion',\n",
    "    'cabbage',\n",
    "    'fourth of july',\n",
    "    'thanksgiving',\n",
    "    'low fat',\n",
    "    'low carb',\n",
    "    'christmas'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(result, min_freq=500, n_features=30):\n",
    "    df = result.loc[result[result.freq >= min_freq].cb_dev.sort_values(ascending=False).index]\n",
    "    cutoff = int(n_features/2)\n",
    "    df_top = list(df[:cutoff].category)\n",
    "    df_bom = list(df[-cutoff:].category)\n",
    "    return df_top + df_bom\n",
    "\n",
    "fts = get_features(result, n_features=24, min_freq=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alcoholic',\n",
       " 'drink',\n",
       " 'cocktail party',\n",
       " 'roast',\n",
       " 'grill',\n",
       " 'thanksgiving',\n",
       " 'low fat',\n",
       " 'christmas',\n",
       " 'backyard bbq',\n",
       " 'grill/barbecue',\n",
       " 'pasta',\n",
       " 'yogurt',\n",
       " 'citrus',\n",
       " 'carrot',\n",
       " 'sauté',\n",
       " 'egg',\n",
       " 'spring',\n",
       " 'lime',\n",
       " 'soup/stew',\n",
       " 'picnic',\n",
       " 'kid-friendly',\n",
       " 'vegetarian',\n",
       " 'breakfast',\n",
       " 'dairy free']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 43, 'gamma': 0.145} 0.590670990272\n"
     ]
    }
   ],
   "source": [
    "samp = raw_data.sample(frac=.2, random_state=101)\n",
    "X = samp[['n_ingredients', 'n_steps', 'n_words', 'n_cats', 'age', 'has_desc'] + features]\n",
    "Y = samp['four_stars']\n",
    "\n",
    "svc = SVC()\n",
    "params = {\n",
    "    'C' : [43, 41],\n",
    "    'gamma' : [.135, .145]\n",
    "}\n",
    "srch = GridSearchCV(svc, params)\n",
    "srch.fit(X, Y)\n",
    "print(srch.best_params_, srch.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samp = raw_data\n",
    "X = samp[['n_ingredients', 'n_steps', 'n_words', 'n_cats', 'age', 'has_desc'] + features]\n",
    "Y = samp['four_stars']\n",
    "\n",
    "svc = SVC(C=43, gamma=.145)\n",
    "rslt = cross_val_score(svc, X, Y)\n",
    "print(rslt.mean(), rslt.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20047, 1000)\n",
      "(20047, 675)\n"
     ]
    }
   ],
   "source": [
    "#Build tfid vectorizer\n",
    "vctzr = TfidfVectorizer(ngram_range=(1, 4), max_features=1000)\n",
    "vctzr.build_analyzer()\n",
    "\n",
    "#Train on recipe corpus\n",
    "vctzr = vctzr.fit(raw_data.dir_doc)\n",
    "\n",
    "#Get sparse matrix of recipe text features\n",
    "A = vctzr.transform(raw_data.dir_doc)\n",
    "trans = random_projection.GaussianRandomProjection(eps=.4)\n",
    "print(A.shape)\n",
    "A_trans = trans.fit_transform(A)\n",
    "print(A_trans.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20047, 40)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features = np.concatenate([A_trans, np.array(raw_data[bin_ft + ['n_ingredients', 'n_steps', 'n_words', 'n_cats']])], axis=1)\n",
    "Y = raw_data['four_stars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=100, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use random forest classifier to select most important features\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(all_features, Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of features selected:  10\n"
     ]
    }
   ],
   "source": [
    "sel = SelectFromModel(clf, prefit=True, threshold=.0019)\n",
    "X_sel = sel.transform(all_features)\n",
    "\n",
    "print('number of features selected: ', X_sel.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 4, 'gamma': 0.41} 0.565228236468\n"
     ]
    }
   ],
   "source": [
    "model_data = pd.DataFrame(data=X_txt, index=raw_data.index)\n",
    "model_data['four_stars'] = raw_data['four_stars']\n",
    "samp = model_data.sample(frac=.2)\n",
    "Y = samp['four_stars']\n",
    "fts = list(samp.columns)\n",
    "fts.remove('four_stars')\n",
    "X = samp[fts]\n",
    "\n",
    "svc = SVC()\n",
    "prms = {\n",
    "    'C' : [3.9, 4],\n",
    "    'gamma' : [.4, .41]\n",
    "}\n",
    "srch = GridSearchCV(svc, prms)\n",
    "srch.fit(X, Y)\n",
    "\n",
    "print(srch.best_params_, srch.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5894156746174262 0.006330587429076657\n"
     ]
    }
   ],
   "source": [
    "model_data = pd.DataFrame(data=X_txt, index=raw_data.index)\n",
    "model_data['four_stars'] = raw_data['four_stars']\n",
    "samp = model_data.sample(frac=1)\n",
    "Y = samp['four_stars']\n",
    "fts = list(samp.columns)\n",
    "fts.remove('four_stars')\n",
    "X = samp[fts]\n",
    "\n",
    "svc = SVC(C=4, gamma=.4)\n",
    "result = pd.Series(cross_val_score(svc, X, Y, cv=5))\n",
    "print(result.mean(), result.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5897632968553241 0.009233711069839182\n"
     ]
    }
   ],
   "source": [
    "print(result.mean(), result.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5355414775278097"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.four_stars.sum()/len(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = raw_data[[\n",
    "    'n_ingredients',\n",
    "    'n_steps',\n",
    "    'n_cats', \n",
    "    'n_words'\n",
    "]\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
